{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd3cc91f238cb11",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Praktikum Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54576aa",
   "metadata": {},
   "source": [
    "1. implementation of normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3309a4a2eb0fa352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T05:36:49.766288200Z",
     "start_time": "2024-09-05T05:36:49.762590200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.16666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def norm_data(data):\n",
    "    \"\"\"\n",
    "    :param data: \n",
    "    :return: \n",
    "    ''''''\n",
    "    Melakukan normalisasi data.\n",
    "    :parameter:\n",
    "        data (list) : Data yang akan dinormalisasi\n",
    "    :returns:\n",
    "        data (list) : Data hasil normalisasi\n",
    "    \"\"\"\n",
    "\n",
    "    data_max = max(data)\n",
    "    data_min = min(data)\n",
    "    data_len = len(data)\n",
    "\n",
    "    for i in range(0, data_len):\n",
    "        data[i] = (data[i] - data_min) / (data_max - data_min)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# contoh\n",
    "data = [10, 11, 12, 14, 16]\n",
    "n_data = norm_data(data)  # melakukan normalisasi\n",
    "print(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8e2f6976ec76c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T05:36:49.766288200Z",
     "start_time": "2024-09-05T05:36:49.766288200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[[100.       0.0001]\n",
      " [ 50.       0.05  ]\n",
      " [ 30.       0.003 ]]\n",
      "Data Normalisasi\n",
      "[[1.       0.      ]\n",
      " [0.285714 1.      ]\n",
      " [0.       0.058116]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.set_printoptions(precision=6) # bulatkan 4 angka koma\n",
    "np.set_printoptions(suppress=True) # hilangkan nilai e\n",
    "\n",
    "# Kita akan membentuk data\n",
    "# Hal ini dikarenakan, scikit-learn hanya menerima input\n",
    "# dalam bentuk n-dimensional array\n",
    "\n",
    "data = [\n",
    "    [100, 0.0001],\n",
    "    [50, 0.05],\n",
    "    [30, 0.003]\n",
    "]\n",
    "\n",
    "# Ubah ke bentuk numpy n-dimensional array\n",
    "data = np.asarray(data)\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "# Mendefinisikan obyek MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Transformasikan dataa\n",
    "scaled = scaler.fit_transform(data)\n",
    "print()\n",
    "print('Data Normalisasi')\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d39491",
   "metadata": {},
   "source": [
    "2. implementation of standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310d7101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[[100.       0.0001]\n",
      " [ 50.       0.05  ]\n",
      " [ 30.       0.003 ]]\n",
      "Data Standarisasi\n",
      "[[ 1.358732 -0.76956 ]\n",
      " [-0.339683  1.412317]\n",
      " [-1.019049 -0.642757]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.set_printoptions(precision=6) # bulatkan 4 angka koma\n",
    "np.set_printoptions(suppress=True) # hilangkan nilai e\n",
    "\n",
    "# Kita akan membentuk data\n",
    "# Hal ini dikarenakan, scikit-learn hanya menerima input\n",
    "# dalam bentuk n-dimensional array\n",
    "\n",
    "data = [\n",
    "    [100, 0.0001],\n",
    "    [50, 0.05],\n",
    "    [30, 0.003]\n",
    "]\n",
    "\n",
    "# Ubah ke bentuk numpy n-dimensional array\n",
    "data = np.asarray(data)\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "\n",
    "# Mendefinisikan obyek StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Transformasikan dataa\n",
    "scaled = scaler.fit_transform(data)\n",
    "print('Data Standarisasi')\n",
    "print(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc048f61",
   "metadata": {},
   "source": [
    "3. Ordinal Encoding Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6595aa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
      "\n",
      "Data Transformasi Ordinal Encoder\n",
      "[[2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Inisiasi obyek Ordinal Encoder\n",
    "oe = OrdinalEncoder()\n",
    "\n",
    "# Definisikan data\n",
    "# dalam bentuk 2d\n",
    "\n",
    "data = [\n",
    "    ['Politeknik Negeri Malang'],\n",
    "    ['Politeknik Elektronika Negeri Surabaya'],\n",
    "    ['Politeknik Negeri Jakarta'],\n",
    "    ['Politeknik Negeri Semarang']\n",
    "]\n",
    "\n",
    "# Transformasi Ordinal Encoder\n",
    "transform_oe = oe.fit_transform(data)\n",
    "\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "print()\n",
    "print('Data Transformasi Ordinal Encoder')\n",
    "print(transform_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1b74c",
   "metadata": {},
   "source": [
    "4. One-Hot Encoding Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cbf3c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
      "\n",
      "Data Transformasi One-Hot Encoding\n",
      "[[0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Inisiasi obyek Ordinal Encoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# Definisikan data\n",
    "# dalam bentuk 2d\n",
    "\n",
    "data = [\n",
    "    ['Politeknik Negeri Malang'],\n",
    "    ['Politeknik Elektronika Negeri Surabaya'],\n",
    "    ['Politeknik Negeri Jakarta'],\n",
    "    ['Politeknik Negeri Semarang']\n",
    "]\n",
    "\n",
    "# Transformasi OneHotEncoder\n",
    "transform_ohe = ohe.fit_transform(data)\n",
    "\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "print()\n",
    "print('Data Transformasi One-Hot Encoding')\n",
    "print(transform_ohe.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56300a99",
   "metadata": {},
   "source": [
    "5. Implementation of Dummy Variable Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5c96f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli\n",
      "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
      "\n",
      "Data Transformasi One-Hot Encoding\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Inisiasi obyek Ordinal Encoder\n",
    "de = OneHotEncoder(drop='first')\n",
    "\n",
    "# Definisikan data\n",
    "# dalam bentuk 2d\n",
    "\n",
    "data = [\n",
    "    ['Politeknik Negeri Malang'],\n",
    "    ['Politeknik Elektronika Negeri Surabaya'],\n",
    "    ['Politeknik Negeri Jakarta'],\n",
    "    ['Politeknik Negeri Semarang']\n",
    "]\n",
    "\n",
    "# Transformasi dummy variable encoding\n",
    "transform_de = de.fit_transform(data)\n",
    "\n",
    "print('Data Asli')\n",
    "print(data)\n",
    "print()\n",
    "print('Data Transformasi One-Hot Encoding')\n",
    "print(transform_de.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f79ae",
   "metadata": {},
   "source": [
    "6. Studi Kasus Ekstrasi Fitur dari Data Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c7947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t0.47557510189256375\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 7)\t0.2808823162882302\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (4, 7)\t0.3193023297639811\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 10)\t0.6700917930430479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Inisiasi obyek TfidVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "corpus = [\n",
    "    'the house had a tiny little mouse',\n",
    "    'the cat saw the mouse',\n",
    "    'the mouse run away from the house',\n",
    "    'the cat finally ate the mouse',\n",
    "    'the end of the mouse story'\n",
    "]\n",
    "\n",
    "# Pembobotan TF-IDF\n",
    "resp = vect.fit_transform(corpus)\n",
    "\n",
    "# Cetak Hasil\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3dc37f",
   "metadata": {},
   "source": [
    "-> Untuk mendapatkan token kata-kata yang didapatkan dari proses stopwords, gunakan perintah seperti pada Kode 1-9. Hasilnya akan seperti pada Gambar 1.11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881bd674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil TF-IDF\n",
      "  (0, 5)\t0.47557510189256375\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 7)\t0.2808823162882302\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (4, 7)\t0.3193023297639811\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 10)\t0.6700917930430479\n",
      "\n",
      "Hasil Token\n",
      "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'run' 'saw'\n",
      " 'story' 'tiny']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'the house had a tiny little mouse',\n",
    "    'the cat saw the mouse',\n",
    "    'the mouse run away from the house',\n",
    "    'the cat finally ate the mouse',\n",
    "    'the end of the mouse story'\n",
    "]\n",
    "\n",
    "# Inisiasi obyek TfidVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Pembobotan TF-IDF\n",
    "resp = vect.fit_transform(corpus)\n",
    "\n",
    "# Cetak Hasil\n",
    "print('Hasil TF-IDF')\n",
    "print(resp)\n",
    "\n",
    "# Cetak token hasil stopword\n",
    "print()\n",
    "print('Hasil Token')\n",
    "print(vect.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffac90d1",
   "metadata": {},
   "source": [
    "## Tugas Praktikum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab13bf",
   "metadata": {},
   "source": [
    "1. Salin kalimat pada Kode 1-7 dengan tanda baca titik pada setiap kalimatnya dengan menggunakan editor teks.\n",
    "2. Simpan kalimat tersebut pada file ‘.txt’ dengan nama ‘corpus.txt’.\n",
    "3. Lakukan proses ektraksi fitur TF-IDF dengan menggunakan file ‘corpus.txt’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dd4af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil TF-IDF\n",
      "  (0, 5)\t0.47557510189256375\n",
      "  (0, 11)\t0.5894630806320427\n",
      "  (0, 6)\t0.5894630806320427\n",
      "  (0, 7)\t0.2808823162882302\n",
      "  (1, 7)\t0.3477147117091919\n",
      "  (1, 2)\t0.5887321837696324\n",
      "  (1, 9)\t0.7297183669435993\n",
      "  (2, 5)\t0.47557510189256375\n",
      "  (2, 7)\t0.2808823162882302\n",
      "  (2, 8)\t0.5894630806320427\n",
      "  (2, 1)\t0.5894630806320427\n",
      "  (3, 7)\t0.2808823162882302\n",
      "  (3, 2)\t0.47557510189256375\n",
      "  (3, 4)\t0.5894630806320427\n",
      "  (3, 0)\t0.5894630806320427\n",
      "  (4, 7)\t0.3193023297639811\n",
      "  (4, 3)\t0.6700917930430479\n",
      "  (4, 10)\t0.6700917930430479\n",
      "\n",
      "Hasil Token\n",
      "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'run' 'saw'\n",
      " 'story' 'tiny']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Inisiasi obyek TfidVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "with open('corpus.txt', 'r') as file:\n",
    "    corpus = file.readlines()\n",
    "\n",
    "# Pembobotan TF-IDF\n",
    "resp = vect.fit_transform(corpus)\n",
    "\n",
    "# Cetak Hasil\n",
    "print('Hasil TF-IDF')\n",
    "print(resp)\n",
    "\n",
    "# Cetak token hasil stopword\n",
    "print()\n",
    "print('Hasil Token')\n",
    "print(vect.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
